# Data Science √ó Logistic Regression

> Harry Potter and the Data Scientist

---

## Sommaire

- [Data Science √ó Logistic Regression](#data-science--logistic-regression)
  - [Sommaire](#sommaire)
  - [1. Avant-propos](#1-avant-propos)
  - [2. Introduction](#2-introduction)
  - [3. Objectifs](#3-objectifs)
  - [4. Instructions g√©n√©rales](#4-instructions-g√©n√©rales)
    - [4.1 Setup et Usage](#41-setup-et-usage)
  - [5. Mandatory Part](#5-mandatory-part)
    - [5.1 Data Analysis](#51-data-analysis)
    - [5.2 Data Visualization](#52-data-visualization)
      - [5.2.1 Histogram](#521-histogram)
      - [5.2.2 Scatter plot](#522-scatter-plot)
      - [5.2.3 Pair plot](#523-pair-plot)
    - [5.3 Logistic Regression](#53-logistic-regression)
  - [6. Bonus Part](#6-bonus-part)
  - [7. Soumission et √©valuation par les pairs](#7-soumission-et-√©valuation-par-les-pairs)

----

## 1. Avant-propos

<details>
<summary><strong>Biographie de Yann Le Cun</strong></summary>

Voici ce que dit Wikip√©dia √† propos de Yann Le Cun, l'un des p√®res fondateurs de l'IA :

**Yann Le Cun** est n√© pr√®s de Paris, en France, en _1960_. Il est chercheur en intelligence
artificielle et en vision par ordinateur (robotique). **Il est consid√©r√© comme l'un des
inventeurs de l'apprentissage profond**.

Titulaire d'une licence de l'ESIEE Paris obtenue en 1983, il est dipl√¥m√© de l'universit√© Pierre
et Marie Curie et a obtenu un doctorat en 1987, au cours duquel il a propos√© une
premi√®re version de **l'algorithme d'apprentissage par r√©tropropagation** couramment utilis√© par les
algorithmes d'optimisation par descente de gradient pour ajuster le poids des neurones en calculant
le gradient de la fonction de perte. Il a √©t√© chercheur postdoctoral associ√© dans le laboratoire
de Geoffrey Hinton √† l'universit√© de Toronto de 1987 √† 1988.

Depuis les ann√©es 1980, _Yann Le Cun travaille sur l'apprentissage automatique_,
la vision par ordinateur et l'apprentissage profond : la capacit√© d'un ordinateur √†
reconna√Ætre des repr√©sentations (images, textes, vid√©os, sons) en les exposant de mani√®re
r√©p√©t√©e √† des √©chantillons d'entra√Ænement.

En 1987, Yann Le Cun rejoint l'universit√© de Toronto, puis, en 1988, les laboratoires de
recherche d'AT&T, o√π il d√©veloppe les m√©thodes d'apprentissage supervis√©.

Yann Le Cun est √©galement l'un des principaux cr√©ateurs de la technologie de compression
d'images DjVu (avec L√©on Bottou et Patrick Haffner).

Yann Le Cun est professeur √† l'universit√© de New York o√π il a cr√©√© le
Center for Data Science. Il travaille notamment sur le d√©veloppement
technologique des voitures autonomes. Il est l'auteur de nombreux ouvrages, dont
¬´ Deep Learning ¬ª (2015) et ¬´ Neural Networks and Machine Learning ¬ª (2013).

Le 9 d√©cembre 2013, Yann Le Cun a √©t√© invit√© par Mark Zuckerberg √† rejoindre Facebook
pour concevoir et diriger le laboratoire d'intelligence artificielle FAIR (¬´ Facebook Artificial Intelligence
Research ¬ª) √† New York, Menlo Park et depuis 2015 √† Paris, afin de travailler sur la reconnaissance d'images.
 Il avait auparavant refus√© une proposition similaire de Google.

En 2016, il a √©t√© professeur invit√© d'informatique √† la ¬´ Chaire Annuelle
Informatique et Sciences Num√©riques ¬ª au Coll√®ge de France √† Paris.
</details>

----

## 2. Introduction

Oh non ! Depuis sa cr√©ation, la c√©l√®bre √©cole de sorciers, Poudlard, n'avait jamais connu une telle
offense. **Les forces du mal ont ensorcel√© le Choixpeau**. Il ne r√©pond plus et
est incapable de remplir son r√¥le qui consiste √† r√©partir les √©l√®ves dans les diff√©rentes maisons.

La nouvelle ann√©e scolaire approche. Heureusement, le professeur McGonagall a pu
prendre des mesures dans une situation aussi stressante, car il est impossible pour Poudlard de ne pas
accueillir de nouveaux √©l√®ves... _Elle a d√©cid√© de faire appel √† vous, un ¬´ data scientist ¬ª moldu qui est
capable de cr√©er des miracles avec l'outil que tous les Moldus savent utiliser : un ¬´ ordinateur ¬ª_.

Malgr√© la r√©ticence intrins√®que de nombreux sorciers, le directeur de l'√©cole vous accueille
dans son bureau pour vous expliquer la situation. Vous √™tes ici parce que son informateur a d√©couvert
que **vous √™tes capable de recr√©er un Choixpeau magique √† l'aide de vos outils moldus**. Vous lui expliquez
que pour que vos outils ¬´ moldus ¬ª fonctionnent, vous avez besoin des donn√©es des √©l√®ves. H√©sitante,
le professeur McGonagall vous remet un livre de sorts poussi√©reux. Heureusement pour vous, un simple
¬´ Digitalis ! ¬ª suffit pour que le livre se transforme en cl√© USB.

----

## 3. Objectifs

Dans ce projet _Data Science √ó R√©gression logistique_, vous poursuivrez votre exploration du
_Machine Learning_ en d√©couvrant diff√©rents outils.

L'utilisation du terme ¬´ science des donn√©es ¬ª dans le titre peut √™tre consid√©r√©e par certains comme excessive.
C'est vrai. Nous ne pr√©tendons pas vous donner toutes les bases de la science des donn√©es dans ce sujet.
Le sujet est vaste. Nous ne couvrirons que certaines bases qui, selon nous, sont utiles pour l'exploration des donn√©es
avant de les envoyer √† l'algorithme d'apprentissage automatique.

Vous allez mettre en ≈ìuvre un **mod√®le de classification lin√©aire** dans le prolongement du sujet sur la r√©gression lin√©aire :
une r√©gression logistique. Nous vous encourageons √©galement √† cr√©er une bo√Æte √† outils d'apprentissage automatique
au fur et √† mesure de votre progression.

En r√©sum√© :

- Vous apprendrez √† lire un ensemble de donn√©es, √† le visualiser de diff√©rentes mani√®res, ainsi qu'√† s√©lectionner et
nettoyer les informations inutiles de vos donn√©es.
- Vous allez entra√Æner un mod√®le de r√©gression logistique qui r√©soudra un probl√®me de classification.

----

## 4. Instructions g√©n√©rales

**Vous pouvez utiliser le langage de votre choix**. Cependant, nous vous recommandons de choisir un langage
disposant d'une biblioth√®que facilitant le trac√© et le calcul des propri√©t√©s statistiques d'un ensemble de donn√©es.

> [!IMPORTANT]
> Toute m√©thode qui effectue tout le travail √† votre place (par exemple, la m√©thode describe()
> d'un DataFrame pandas) sera consid√©r√©e comme de la triche.

### 4.1 Setup et Usage

üîπ <strong>√âtape 1 : Cr√©er un environnement virtuel</strong>

```bash
# Cr√©er l'environnement
python3 -m venv venv

# Activer l'environnement
source venv/bin/activate

# Desactiver l'environnement
deactivate
```

üîπ <strong>√âtape 2 : Installer les d√©pendances</strong>

Mettre a jour pip :
```bash
pip install --upgrade pip
```


```bash
pip install -r requirements.txt
```

V√©rifier l‚Äôinstallation :

```bash
pip list
```

Geler les versions :

```bash
pip freeze > requirements.txt
```

----

## 5. Mandatory Part

> [!NOTE]
> Il est fortement recommand√© d'effectuer les √©tapes dans l'ordre suivant.

### 5.1 Data Analysis

> [!IMPORTANT]
> Nous allons voir quelques √©tapes fondamentales de l'exploration des donn√©es. Bien s√ªr, ce
> ne sont pas les seules techniques disponibles ni les seules √©tapes √† suivre.
> Chaque ensemble de donn√©es et chaque probl√®me doivent √™tre abord√©s de mani√®re unique. Vous
> trouverez certainement d'autres fa√ßons d'analyser vos donn√©es √† l'avenir.

Tout d'abord, examinez les donn√©es disponibles. Regardez sous quel format elles sont pr√©sent√©es,
s'il existe diff√©rents types de donn√©es, les diff√©rentes plages, etc. Il est important de
vous faire une id√©e de votre mati√®re premi√®re avant de commencer. Plus vous travaillerez avec les donn√©es, plus
vous d√©velopperez une intuition sur la mani√®re dont vous pourrez les utiliser.

Dans cette partie, le professeur McGonagall vous demande de cr√©er un programme appel√© `describe.[extension]`.<br>
Ce programme prendra un ensemble de donn√©es comme param√®tre. Il devra simplement afficher les informations
relatives √† toutes les caract√©ristiques num√©riques, comme dans l'exemple suivant :

> [!IMPORTANT]
> Il est interdit d'utiliser toute fonction qui effectue le travail √† votre place, telle que :
> count, mean, std, min, max, percentile, etc., quel que soit le
> langage que vous utilisez. Bien s√ªr, il est √©galement interdit d'utiliser la
> biblioth√®que describe ou toute fonction qui lui ressemble (plus ou moins)
> provenant d'une autre biblioth√®que.

----

### 5.2 Data Visualization

La visualisation des donn√©es est un outil puissant pour un data scientist. Elle vous permet d'obtenir des informations
et de d√©velopper une intuition sur l'aspect de vos donn√©es. La visualisation de vos donn√©es vous permet √©galement
de d√©tecter des d√©fauts ou des anomalies.

Dans cette section, **vous devez cr√©er un ensemble de scripts**, chacun utilisant une m√©thode de visualisation particuli√®re
pour r√©pondre √† une question. Il n'y a pas n√©cessairement une seule r√©ponse √† la
question.

#### 5.2.1 Histogram

Cr√©ez un script appel√© **`histogram.[extension]`** qui affiche un histogramme r√©pondant √† la
question suivante :

    - Quel cours √† Poudlard pr√©sente une r√©partition homog√®ne des notes entre les quatre maisons ?

#### 5.2.2 Scatter plot

Cr√©ez un script appel√© **`scatter_plot.[extension]`** qui affiche un nuage de points r√©pondant √† la question suivante :

    - Quelles sont les deux caract√©ristiques qui sont similaires ?

#### 5.2.3 Pair plot

Cr√©ez un script appel√© **`pair_plot.[extension]`** qui affiche un graphique en paires ou un nuage de points
(selon la biblioth√®que que vous utilisez).

    - √Ä partir de cette visualisation, quelles caract√©ristiques allez-vous utiliser pour votre r√©gression logistique ?

----

### 5.3 Logistic Regression

Vous arrivez √† _la derni√®re partie_ : c**oder votre Magic Hat**. Pour ce faire, vous devez _effectuer un
multi-classificateur_ √† l'aide d'une r√©gression logistique one-vs-all (one-vs-rest).

Vous devrez cr√©er deux programmes :
- Le premier servira √† entra√Æner vos mod√®les et s'appelle **`logreg_train.[extension`**].
Il prend **dataset_train.csv** comme param√®tre. _Pour la partie obligatoire, vous devez
utiliser la technique de descente de gradient afin de minimiser l'erreur_. Le programme g√©n√®re
un fichier contenant les poids qui seront utilis√©s pour la pr√©diction.
- Le second doit √™tre nomm√© **`logreg_predict.[extension]`**. Il prend dataset_test.csv
comme param√®tre et un fichier contenant les poids entra√Æn√©s par le programme pr√©c√©dent.

Afin d'√©valuer les performances de votre classificateur, ce deuxi√®me programme devra
g√©n√©rer un fichier de pr√©diction houses.csv format√© exactement comme suit :

```bash
$> cat houses.csv
Index,Hogwarts House
0,Gryffindor
1,Hufflepuff
2,Ravenclaw
3,Hufflepuff
4,Slytherin
5,Ravenclaw
6,Hufflepuff
[...]
```

----

## 6. Bonus Part

Il existe de nombreux bonus int√©ressants qui peuvent √™tre ajout√©s √† ce sujet. Voici quelques
suggestions :

- Ajouter d'autres champs pour **`describe.[extension]`**
- Impl√©mente **stochastic gradient descent**
- Impl√©menter d'autres algorithmes d'optimisation (GD par lots, GD par mini-lots ou autres)

> [!IMPORTANT]
> La partie bonus ne sera √©valu√©e que si la partie obligatoire est
> PARFAITE. Parfaite signifie que la partie obligatoire a √©t√© enti√®rement
> r√©alis√©e et fonctionne sans aucun probl√®me. Si vous n'avez pas satisfait √† TOUTES
> les exigences obligatoires, votre partie bonus ne sera pas √©valu√©e.

----

## 7. Soumission et √©valuation par les pairs

Remettez votre devoir dans votre d√©p√¥t Git comme d'habitude. Seul le travail contenu dans votre d√©p√¥t
sera √©valu√© lors de la soutenance. N'h√©sitez pas √† v√©rifier les noms de vos
dossiers et fichiers pour vous assurer qu'ils sont corrects.

Pendant la correction, vous serez √©valu√© sur votre travail rendu (aucune fonction ne fera
tout le travail √† votre place), ainsi que sur votre capacit√© √† pr√©senter, expliquer et justifier vos
choix.

Votre classificateur sera √©valu√© sur les donn√©es pr√©sentes dans dataset_test.csv. Vos r√©ponses
seront √©valu√©es √† l'aide du score de pr√©cision de la biblioth√®que Scikit-Learn. Le professeur
McGonagall estime que votre algorithme n'est comparable au Choixpeau magique que s'il obtient un
score de pr√©cision minimum de 98 %.

Il sera √©galement important de pouvoir expliquer le fonctionnement des algorithmes d'apprentissage automatique
utilis√©s.
